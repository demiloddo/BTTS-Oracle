{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load datasets\n",
    "dataset = pd.read_csv(\"/Users/albertoloddo/Documents/Demetrio 2012/Desktop_Air_2012/BTTS Oracle/Datasets/italy-serie-a-teams-2022-to-2023-stats.csv\")\n",
    "matches = pd.read_csv(\"/Users/albertoloddo/Documents/Demetrio 2012/Desktop_Air_2012/BTTS Oracle/Datasets/italy-serie-a-matches-2022-to-2023-stats.csv\")\n",
    "fifa = pd.read_csv(\"/Users/albertoloddo/Documents/Demetrio 2012/Desktop_Air_2012/BTTS Oracle/Datasets/teams_fifa23.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This preprocessing phase is crucial for generating both historical and real-time insights into team performance, with the creation of new derived features that will be valuable for predictive modeling tasks. The key features include:\n",
    "\n",
    "- **average_goals_home/away** and **recent_goals_home/away**: These provide insights into each team's offensive capabilities over different periods of the season, calculated both as cumulative averages and recent performance metrics. These metrics allow models to capture trends in a team's attacking form over time.\n",
    "- **average_conceeded_home/away** and **recent_conceeded_home/away**: Similar to the goals features, these statistics offer information about a team's defensive vulnerabilities, indicating how many goals they typically concede at home and away, both in aggregate and based on recent match performance.\n",
    "- **average_shots_home/away** and **recent_shots_home/away**: These derived shot statistics provide an indication of the attacking strength of each team, measured both across the whole season and over the most recent matches. They help assess how likely a team is to create attacking opportunities and challenge opposing defenses.\n",
    "- **goal_home_team** and **goal_away_team**: These computed values reflect the relative strength of each team's attack and defense, considering how the home and away team's strengths interact. The home team’s offensive strength is compared to the away team’s defensive capabilities and vice versa.\n",
    "- **attack_game** and **defence_game**: These final combined metrics summarize the overall attacking and defensive strength of each team, providing a more holistic assessment of their footballing capabilities.\n",
    "\n",
    "This wealth of derived features is essential for making more accurate predictions about future matches. The preprocessing approach also takes particular care with the split between training and test datasets. Using the **cut_off** variable, this pipeline ensures that only data available up to a certain matchweek (the cut-off point) is used for building predictive models. This prevents any potential data leakage where information from future games could unfairly influence the model, ensuring that it reflects the real-world scenario where predictions must be made without knowledge of future outcomes.\n",
    "\n",
    "The final `preprocessed_df` dataset is enriched with these time-sensitive, match-specific features, making it ready for use in predictive models. This dataset accurately represents a team's cumulative performance up until the defined cut-off match and allows the exploration of trends, interactions, and patterns in the context of football matches over time. It is optimized for predictive tasks where accurate, performance-based forecasts are necessary, giving an edge in sports analytics applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PREPROCESSING\n",
    "# Filter FIFA data\n",
    "fifa = fifa[fifa[\"League\"] == \"Italian Serie A (1)\"]\n",
    "fifa.reset_index(drop=True, inplace=True)  # This will reindex the dataset from 0\n",
    "\n",
    "# List of index positions (from your previous code)\n",
    "indexes = [1, 7, 14, 15, 16, 17, 18, 19]  # Update this list based on your specific indexes\n",
    "team_names = [\"Monza\", \"Inter Milan\", \"Torino\", \"Sampdoria\", \"Sassuolo\", \"Cremonese\", \"Salernitana\", \"Udinese\"]\n",
    "\n",
    "# Replacing 'Name' at the specified indices\n",
    "for idx, team_name in zip(indexes, team_names):\n",
    "    # Update 'Name' value at each given index\n",
    "    if idx < len(fifa):  # Ensure the index is within the range of the dataset\n",
    "        fifa.loc[idx, \"Name\"] = team_name\n",
    "    else:\n",
    "        print(f\"Warning: Index {idx} is out of bounds.\")\n",
    "\n",
    "\n",
    "# Create new columns in matches\n",
    "matches[\"delta_ppg\"] = matches[\"Pre-Match PPG (Home)\"] - matches[\"Pre-Match PPG (Away)\"]\n",
    "matches[\"btts\"] = np.where((matches[\"away_team_goal_count\"] != 0) & (matches[\"home_team_goal_count\"] != 0), 1, 0)\n",
    "#half_home and half_away are binary values to know whereas the home team or the away team has scored at half time\n",
    "matches[\"half_home\"] = np.where((matches[\"home_team_goal_count_half_time\"] != 0), 1, 0)\n",
    "matches[\"half_away\"] = np.where((matches[\"away_team_goal_count_half_time\"] != 0), 1, 0)\n",
    "\n",
    "# Datasets of played matches (until the 21st game of the season) where variables are added from existing ones   \n",
    "preprocessed_df = matches[matches[\"Game Week\"] <= 21].copy()\n",
    "preprocessed_df = preprocessed_df.sort_values(by=\"Game Week\")\n",
    "\n",
    "# Initialize variables\n",
    "team = dataset['common_name']\n",
    "\n",
    "# The variable `cut_off` represents the point in the dataset where historical data is divided\n",
    "# from the future games we want to predict. All statistics and features used for model training\n",
    "# are calculated based on data up to this point, ensuring the model does not have access to\n",
    "# future information that would otherwise cause data leakage. Predictions are made for games\n",
    "# occurring after the `cut_off` point\n",
    "cut_off = 16  \n",
    "\n",
    "# Initialize lists to store cumulative and recent averages for each team\n",
    "sum_goals_home, sum_goals_away = [], []\n",
    "week_home, week_away = [], []\n",
    "recent_home, recent_away = [], []\n",
    "counter_home, counter_away = 0, 0\n",
    "# Loop through each team in the team list\n",
    "for team_name in team:\n",
    "    # Process each row in preprocessed_df\n",
    "    for i, row in preprocessed_df.iterrows():\n",
    "        # Process home team\n",
    "        if row['home_team_name'] == team_name:\n",
    "            sum_goals_home.append(row['home_team_goal_count'])\n",
    "            week_home.append(np.mean(sum_goals_home))\n",
    "            recent_home.append(np.mean(sum_goals_home[-5:]) if len(sum_goals_home) >= 5 else np.mean(sum_goals_home))\n",
    "\n",
    "            # Apply cut_off condition\n",
    "            if row['Game Week'] <= cut_off:\n",
    "                # Update values based on current calculations\n",
    "                preprocessed_df.at[i, 'average_goals_home'] = week_home[counter_home]\n",
    "                preprocessed_df.at[i, 'recent_goals_home'] = recent_home[counter_home]\n",
    "            else:\n",
    "                # Use last pre-cut_off values for post-cut_off games\n",
    "                preprocessed_df.at[i, 'average_goals_home'] = week_home[counter_home - 1]\n",
    "                preprocessed_df.at[i, 'recent_goals_home'] = recent_home[counter_home - 1]\n",
    "            \n",
    "            counter_home += 1\n",
    "\n",
    "        # Process away team\n",
    "        if row['away_team_name'] == team_name:\n",
    "            sum_goals_away.append(row['away_team_goal_count'])\n",
    "            week_away.append(np.mean(sum_goals_away))\n",
    "            recent_away.append(np.mean(sum_goals_away[-5:]) if len(sum_goals_away) >= 5 else np.mean(sum_goals_away))\n",
    "\n",
    "            # Apply cut_off condition\n",
    "            if row['Game Week'] <= cut_off:\n",
    "                # Update values based on current calculations\n",
    "                preprocessed_df.at[i, 'average_goals_away'] = week_away[counter_away]\n",
    "                preprocessed_df.at[i, 'recent_goals_away'] = recent_away[counter_away]\n",
    "            else:\n",
    "                # Use last pre-cut_off values for post-cut_off games\n",
    "                preprocessed_df.at[i, 'average_goals_away'] = week_away[counter_away - 1]\n",
    "                preprocessed_df.at[i, 'recent_goals_away'] = recent_away[counter_away - 1]\n",
    "            \n",
    "            counter_away += 1\n",
    "    sum_goals_home, sum_goals_away = [], [] \n",
    "    week_home, week_away = [], []\n",
    "    recent_home, recent_away = [], []\n",
    "    counter_home, counter_away = 0, 0\n",
    "\n",
    "# Loop through each team in the team list\n",
    "for team_name in team:\n",
    "    # Process each row in preprocessed_df\n",
    "    for i, row in preprocessed_df.iterrows():\n",
    "        # Process home team\n",
    "        if row['home_team_name'] == team_name:\n",
    "            sum_goals_home.append(row['away_team_goal_count'])\n",
    "            week_home.append(np.mean(sum_goals_home))\n",
    "            recent_home.append(np.mean(sum_goals_home[-5:]) if len(sum_goals_home) >= 5 else np.mean(sum_goals_home))\n",
    "\n",
    "            # Apply cut_off condition\n",
    "            if row['Game Week'] <= cut_off:\n",
    "                # Update values based on current calculations\n",
    "                preprocessed_df.at[i, 'avarage_conceeded_home'] = week_home[counter_home]\n",
    "                preprocessed_df.at[i, 'recent_conceeded_home'] = recent_home[counter_home]\n",
    "            else:\n",
    "                # Use last pre-cut_off values for post-cut_off games\n",
    "                preprocessed_df.at[i, 'avarage_conceeded_home'] = week_home[counter_home - 1]\n",
    "                preprocessed_df.at[i, 'recent_conceeded_home'] = recent_home[counter_home - 1]\n",
    "            \n",
    "            counter_home += 1\n",
    "\n",
    "        # Process away team\n",
    "        if row['away_team_name'] == team_name:\n",
    "            sum_goals_away.append(row['home_team_goal_count'])\n",
    "            week_away.append(np.mean(sum_goals_away))\n",
    "            recent_away.append(np.mean(sum_goals_away[-5:]) if len(sum_goals_away) >= 5 else np.mean(sum_goals_away))\n",
    "\n",
    "            # Apply cut_off condition\n",
    "            if row['Game Week'] <= cut_off:\n",
    "                # Update values based on current calculations\n",
    "                preprocessed_df.at[i, 'avarage_conceeded_away'] = week_away[counter_away]\n",
    "                preprocessed_df.at[i, 'recent_conceeded_away'] = recent_away[counter_away]\n",
    "            else:\n",
    "                # Use last pre-cut_off values for post-cut_off games\n",
    "                preprocessed_df.at[i, 'avarage_conceeded_away'] = week_away[counter_away - 1]\n",
    "                preprocessed_df.at[i, 'recent_conceeded_away'] = recent_away[counter_away - 1]\n",
    "            \n",
    "            counter_away += 1\n",
    "    sum_goals_home, sum_goals_away = [], [] \n",
    "    week_home, week_away = [], []\n",
    "    recent_home, recent_away = [], []\n",
    "    counter_home, counter_away = 0, 0\n",
    "\n",
    "# Loop through each team in the team list\n",
    "for team_name in team:\n",
    "    # Process each row in preprocessed_df\n",
    "    for i, row in preprocessed_df.iterrows():\n",
    "        # Process home team\n",
    "        if row['home_team_name'] == team_name:\n",
    "            sum_goals_home.append(row['home_team_shots_on_target'])\n",
    "            week_home.append(np.mean(sum_goals_home))\n",
    "            recent_home.append(np.mean(sum_goals_home[-5:]) if len(sum_goals_home) >= 5 else np.mean(sum_goals_home))\n",
    "\n",
    "            # Apply cut_off condition\n",
    "            if row['Game Week'] <= cut_off:\n",
    "                # Update values based on current calculations\n",
    "                preprocessed_df.at[i, 'avarage_shots_home'] = week_home[counter_home]\n",
    "                preprocessed_df.at[i, 'recent_shots_home'] = recent_home[counter_home]\n",
    "            else:\n",
    "                # Use last pre-cut_off values for post-cut_off games\n",
    "                preprocessed_df.at[i, 'avarage_shots_home'] = week_home[counter_home - 1]\n",
    "                preprocessed_df.at[i, 'recent_shots_home'] = recent_home[counter_home - 1]\n",
    "            \n",
    "            counter_home += 1\n",
    "\n",
    "        # Process away team\n",
    "        if row['away_team_name'] == team_name:\n",
    "            sum_goals_away.append(row['away_team_shots_on_target'])\n",
    "            week_away.append(np.mean(sum_goals_away))\n",
    "            recent_away.append(np.mean(sum_goals_away[-5:]) if len(sum_goals_away) >= 5 else np.mean(sum_goals_away))\n",
    "\n",
    "            # Apply cut_off condition\n",
    "            if row['Game Week'] <= cut_off:\n",
    "                # Update values based on current calculations\n",
    "                preprocessed_df.at[i, 'avarage_shots_away'] = week_away[counter_away]\n",
    "                preprocessed_df.at[i, 'recent_shots_away'] = recent_away[counter_away]\n",
    "            else:\n",
    "                # Use last pre-cut_off values for post-cut_off games\n",
    "                preprocessed_df.at[i, 'avarage_shots_away'] = week_away[counter_away - 1]\n",
    "                preprocessed_df.at[i, 'recent_shots_away'] = recent_away[counter_away - 1]\n",
    "            \n",
    "            counter_away += 1\n",
    "    sum_goals_home, sum_goals_away = [], [] \n",
    "    week_home, week_away = [], []\n",
    "    recent_home, recent_away = [], []\n",
    "    counter_home, counter_away = 0, 0\n",
    "\n",
    "\n",
    "# Initialize the columns in the training dataset\n",
    "preprocessed_df['percentage_half_home_conceded'] = np.nan\n",
    "preprocessed_df['percentage_half_away_conceded'] = np.nan\n",
    "preprocessed_df['recent_percentage_half_home_conceded'] = np.nan\n",
    "preprocessed_df['recent_percentage_half_away_conceded'] = np.nan\n",
    "\n",
    "# Loop over each team and calculate percentages\n",
    "for k in range(len(team)):\n",
    "    half_home = []\n",
    "    half_away = []\n",
    "    recent_home = []\n",
    "    recent_away = []\n",
    "    percentage_home = []\n",
    "    percentage_away = []\n",
    "    counter_home, counter_away = 0, 0\n",
    "\n",
    "    for i, row in preprocessed_df.iterrows():\n",
    "        # Process for home team\n",
    "        if row['home_team_name'] == team[k]:\n",
    "            half_home.append(preprocessed_df.loc[i, 'half_away'])\n",
    "            percentage_home.append(np.mean(np.array(half_home) == 1))\n",
    "            if len(half_home) >= 3:\n",
    "                recent_home.append(np.mean(np.array(half_home[-3:]) == 1))\n",
    "            else:\n",
    "                recent_home.append(np.mean(np.array(half_home) == 1))\n",
    "            \n",
    "            if i < (len(preprocessed_df) - len(preprocessed_df[preprocessed_df['Game Week'] > cut_off])):\n",
    "                preprocessed_df.loc[i, 'percentage_half_home_conceded'] = percentage_home[counter_home]\n",
    "                preprocessed_df.loc[i, 'recent_percentage_half_home_conceded'] = recent_home[counter_home]\n",
    "            else:\n",
    "                preprocessed_df.loc[i, 'percentage_half_home_conceded'] = percentage_home[counter_home - 1]\n",
    "                preprocessed_df.loc[i, 'recent_percentage_half_home_conceded'] = recent_home[counter_home - 1]\n",
    "            \n",
    "            counter_home += 1\n",
    "\n",
    "        # Process for away team\n",
    "        if row['away_team_name'] == team[k]:\n",
    "            half_away.append(preprocessed_df.loc[i, 'half_home'])\n",
    "            percentage_away.append(np.mean(np.array(half_away) == 1))\n",
    "            if len(half_away) >= 3:\n",
    "                recent_away.append(np.mean(np.array(half_away[-3:]) == 1))\n",
    "            else:\n",
    "                recent_away.append(np.mean(np.array(half_away) == 1))\n",
    "            \n",
    "            if i < (len(preprocessed_df) - len(preprocessed_df[preprocessed_df['Game Week'] > cut_off])):\n",
    "                preprocessed_df.loc[i, 'percentage_half_away_conceded'] = percentage_away[counter_away]\n",
    "                preprocessed_df.loc[i, 'recent_percentage_half_away_conceded'] = recent_away[counter_away]\n",
    "            else:\n",
    "                preprocessed_df.loc[i, 'percentage_half_away_conceded'] = percentage_away[counter_away - 1]\n",
    "                preprocessed_df.loc[i, 'recent_percentage_half_away_conceded'] = recent_away[counter_away - 1]\n",
    "            \n",
    "            counter_away += 1\n",
    "\n",
    "# Initialize additional columns with NaN\n",
    "preprocessed_df['attack_away'] = np.nan\n",
    "preprocessed_df['attack_home'] = np.nan\n",
    "preprocessed_df['defence_away'] = np.nan\n",
    "preprocessed_df['defence_home'] = np.nan\n",
    "\n",
    "# Update attack and defense values using the FIFA dataset\n",
    "for k in range(len(team)):\n",
    "    team_name = team[k]\n",
    "    attack_value = fifa.loc[fifa['Name'] == team_name, 'Attack'].values[0]\n",
    "    defence_value = fifa.loc[fifa['Name'] == team_name, 'Defence'].values[0]\n",
    "    \n",
    "    preprocessed_df.loc[preprocessed_df['home_team_name'] == team_name, 'attack_home'] = attack_value\n",
    "    preprocessed_df.loc[preprocessed_df['home_team_name'] == team_name, 'defence_home'] = defence_value\n",
    "    preprocessed_df.loc[preprocessed_df['away_team_name'] == team_name, 'attack_away'] = attack_value\n",
    "    preprocessed_df.loc[preprocessed_df['away_team_name'] == team_name, 'defence_away'] = defence_value\n",
    "\n",
    "# Calculating goal differences and total attack/defense metrics\n",
    "preprocessed_df['goal_home_team'] = preprocessed_df['defence_away'] - preprocessed_df['attack_home']\n",
    "preprocessed_df['goal_away_team'] = preprocessed_df['defence_home'] - preprocessed_df['attack_away']\n",
    "preprocessed_df['attack_game'] = preprocessed_df['attack_away'] + preprocessed_df['attack_home']\n",
    "preprocessed_df['defence_game'] = preprocessed_df['defence_home'] + preprocessed_df['defence_away']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTIVE MODELLING \n",
    "\n",
    "# Define feature set (remove features that are unavailable during gametime) and target variable\n",
    "X = preprocessed_df.drop(columns=[\n",
    "    \"away_team_shots_on_target\", \"home_team_shots_on_target\", \"home_team_goal_count_half_time\",\n",
    "    \"away_team_goal_count_half_time\", \"total_goals_at_half_time\", \"total_goal_count\",\n",
    "    \"home_team_goal_count\", \"away_team_goal_count\", \"btts\", \"Game Week\", \"timestamp\", \"date_GMT\",\n",
    "    \"status\", 'home_team_name', 'away_team_name', 'referee', 'home_team_goal_timings',\n",
    "    'away_team_goal_timings', 'stadium_name', 'half_home', 'half_away', 'attendance'\n",
    "])\n",
    "y = preprocessed_df[\"btts\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section splits the dataset into training and testing sets using the `cut_off` based on \"Game Week.\" It applies Recursive Feature Elimination (RFE) with a Random Forest Classifier to select the top 10 features from the training data. The training and test sets are then transformed to keep only these selected features. A Random Forest model is trained on the filtered data and used to predict the probability of BTTS (both teams to score) for the test set. Custom thresholding is applied, classifying values above 0.6 as 1 and below 0.4 as 0, with values between 0.4 and 0.6 set to `NaN`. The accuracy is calculated after filtering out uncertain predictions. A comparison DataFrame is generated for manual inspection, and the feature importance from the model is displayed to evaluate the significance of selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom threshold accuracy (excluding values between 0.4 and 0.6): 57.14%\n",
      "    True Value (y_test)  Predicted Value (y_pred)  \\\n",
      "0                     0                       1.0   \n",
      "1                     1                       1.0   \n",
      "2                     0                       0.0   \n",
      "3                     0                       1.0   \n",
      "4                     1                       1.0   \n",
      "5                     1                       1.0   \n",
      "6                     0                       0.0   \n",
      "7                     1                       1.0   \n",
      "8                     1                       0.0   \n",
      "9                     0                       0.0   \n",
      "10                    1                       1.0   \n",
      "11                    1                       1.0   \n",
      "12                    0                       1.0   \n",
      "13                    1                       1.0   \n",
      "14                    1                       0.0   \n",
      "15                    0                       0.0   \n",
      "16                    1                       0.0   \n",
      "17                    0                       0.0   \n",
      "18                    1                       1.0   \n",
      "19                    0                       1.0   \n",
      "20                    0                       1.0   \n",
      "21                    0                       1.0   \n",
      "22                    0                       0.0   \n",
      "23                    0                       1.0   \n",
      "24                    0                       1.0   \n",
      "25                    1                       0.0   \n",
      "26                    1                       1.0   \n",
      "27                    1                       1.0   \n",
      "28                    0                       0.0   \n",
      "29                    1                       1.0   \n",
      "30                    1                       0.0   \n",
      "31                    1                       1.0   \n",
      "32                    0                       0.0   \n",
      "33                    0                       1.0   \n",
      "34                    0                       0.0   \n",
      "35                    0                       0.0   \n",
      "36                    0                       1.0   \n",
      "37                    0                       1.0   \n",
      "38                    0                       1.0   \n",
      "39                    1                       1.0   \n",
      "40                    1                       1.0   \n",
      "41                    0                       1.0   \n",
      "\n",
      "    Predicted Probability (BTTS)  \n",
      "0                           0.86  \n",
      "1                           0.88  \n",
      "2                           0.02  \n",
      "3                           0.97  \n",
      "4                           0.68  \n",
      "5                           1.00  \n",
      "6                           0.20  \n",
      "7                           0.61  \n",
      "8                           0.31  \n",
      "9                           0.37  \n",
      "10                          0.85  \n",
      "11                          0.95  \n",
      "12                          0.93  \n",
      "13                          0.99  \n",
      "14                          0.08  \n",
      "15                          0.20  \n",
      "16                          0.10  \n",
      "17                          0.22  \n",
      "18                          0.88  \n",
      "19                          0.77  \n",
      "20                          0.98  \n",
      "21                          0.94  \n",
      "22                          0.06  \n",
      "23                          0.86  \n",
      "24                          0.79  \n",
      "25                          0.27  \n",
      "26                          0.73  \n",
      "27                          0.78  \n",
      "28                          0.38  \n",
      "29                          0.78  \n",
      "30                          0.27  \n",
      "31                          0.93  \n",
      "32                          0.32  \n",
      "33                          0.69  \n",
      "34                          0.33  \n",
      "35                          0.29  \n",
      "36                          0.95  \n",
      "37                          0.62  \n",
      "38                          0.65  \n",
      "39                          0.97  \n",
      "40                          0.84  \n",
      "41                          0.93  \n",
      "                         Feature  Importance\n",
      "0             average_goals_away    0.140659\n",
      "7          recent_conceeded_home    0.127316\n",
      "6         avarage_conceeded_home    0.104031\n",
      "2             average_goals_home    0.103804\n",
      "3              recent_goals_home    0.098898\n",
      "1              recent_goals_away    0.094504\n",
      "9  percentage_half_home_conceded    0.089678\n",
      "4         avarage_conceeded_away    0.084182\n",
      "5          recent_conceeded_away    0.082205\n",
      "8             avarage_shots_home    0.074722\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train = X[preprocessed_df['Game Week'] <= cut_off]\n",
    "y_train = y[preprocessed_df['Game Week'] <= cut_off]\n",
    "X_test = X[preprocessed_df['Game Week'] > cut_off]\n",
    "y_test = y[preprocessed_df['Game Week'] > cut_off]\n",
    "\n",
    "# Initialize Random Forest Classifier for RFE\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Apply RFE for feature selection on training data only\n",
    "selector = RFE(estimator=rf, n_features_to_select=10)  # Choose the number of features you want to select\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected feature names from the selector\n",
    "selected_columns = X_train.columns[selector.support_]\n",
    "\n",
    "# Transform the training and test data to keep only the selected features\n",
    "X_train_selected = X_train[selected_columns]\n",
    "X_test_selected = X_test[selected_columns]\n",
    "\n",
    "# Train Random Forest on selected features\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob = rf_model.predict_proba(X_test_selected)[:, 1]  # Probability of BTTS (1)\n",
    "\n",
    "# Apply custom thresholding\n",
    "y_pred_custom = np.where(y_pred_prob >= 0.6, 1, np.where(y_pred_prob <= 0.4, 0, np.nan))\n",
    "\n",
    "# Filter out NaN values for both y_pred_custom and y_test\n",
    "mask = ~np.isnan(y_pred_custom)\n",
    "y_test_filtered = y_test[mask].reset_index(drop=True)\n",
    "y_pred_filtered = pd.Series(y_pred_custom[mask]).reset_index(drop=True)\n",
    "\n",
    "# Calculate accuracy on filtered predictions\n",
    "accuracy = accuracy_score(y_test_filtered, y_pred_filtered)\n",
    "print(f\"Custom threshold accuracy (excluding values between 0.4 and 0.6): {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display a comparison DataFrame for manual inspection\n",
    "comparison_df = pd.DataFrame({\n",
    "    'True Value (y_test)': y_test_filtered,\n",
    "    'Predicted Value (y_pred)': y_pred_filtered,\n",
    "    'Predicted Probability (BTTS)': y_pred_prob[mask]\n",
    "})\n",
    "print(comparison_df)\n",
    "\n",
    "# Get feature importance from the trained Random Forest model\n",
    "importances = rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': selected_columns,  # Use selected columns names\n",
    "    'Importance': importances\n",
    "})\n",
    "print(feature_importance_df.sort_values(by='Importance', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code splits the dataset into training and testing sets based on a `cut_off` value corresponding to \"Game Week.\" It initializes an XGBoost classifier with 100 estimators, then trains the model using the training data (`X_train` and `y_train`). After making predictions on the test data, it applies custom thresholding to classify predictions based on probabilities—assigning 1 for values above 0.6, 0 for those below 0.4, and `NaN` for intermediate values. Predictions and true values are filtered to exclude `NaN` entries before calculating accuracy. A comparison DataFrame is generated for manual inspection, and the feature importance is extracted from the trained XGBoost model and displayed in descending order to highlight the most influential features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom threshold accuracy (excluding values between 0.4 and 0.6): 52.08%\n",
      "    True Value (y_test)  Predicted Value (y_pred)  \\\n",
      "0                     0                       1.0   \n",
      "1                     1                       1.0   \n",
      "2                     0                       0.0   \n",
      "3                     0                       1.0   \n",
      "4                     1                       1.0   \n",
      "5                     1                       1.0   \n",
      "6                     1                       0.0   \n",
      "7                     0                       0.0   \n",
      "8                     1                       1.0   \n",
      "9                     1                       0.0   \n",
      "10                    0                       0.0   \n",
      "11                    0                       1.0   \n",
      "12                    1                       1.0   \n",
      "13                    1                       1.0   \n",
      "14                    0                       1.0   \n",
      "15                    0                       1.0   \n",
      "16                    1                       1.0   \n",
      "17                    1                       0.0   \n",
      "18                    1                       0.0   \n",
      "19                    0                       0.0   \n",
      "20                    1                       0.0   \n",
      "21                    0                       0.0   \n",
      "22                    1                       1.0   \n",
      "23                    0                       1.0   \n",
      "24                    0                       1.0   \n",
      "25                    0                       1.0   \n",
      "26                    0                       0.0   \n",
      "27                    0                       1.0   \n",
      "28                    1                       0.0   \n",
      "29                    1                       1.0   \n",
      "30                    1                       1.0   \n",
      "31                    0                       0.0   \n",
      "32                    1                       0.0   \n",
      "33                    1                       1.0   \n",
      "34                    1                       0.0   \n",
      "35                    1                       0.0   \n",
      "36                    1                       1.0   \n",
      "37                    0                       0.0   \n",
      "38                    0                       1.0   \n",
      "39                    1                       1.0   \n",
      "40                    0                       0.0   \n",
      "41                    0                       1.0   \n",
      "42                    0                       1.0   \n",
      "43                    0                       1.0   \n",
      "44                    1                       1.0   \n",
      "45                    0                       0.0   \n",
      "46                    1                       1.0   \n",
      "47                    0                       1.0   \n",
      "\n",
      "    Predicted Probability (BTTS)  \n",
      "0                       0.825770  \n",
      "1                       0.810240  \n",
      "2                       0.095305  \n",
      "3                       0.987333  \n",
      "4                       0.737552  \n",
      "5                       0.993986  \n",
      "6                       0.092087  \n",
      "7                       0.077955  \n",
      "8                       0.856768  \n",
      "9                       0.133455  \n",
      "10                      0.300270  \n",
      "11                      0.945600  \n",
      "12                      0.937121  \n",
      "13                      0.996999  \n",
      "14                      0.947099  \n",
      "15                      0.991012  \n",
      "16                      0.973525  \n",
      "17                      0.036921  \n",
      "18                      0.234984  \n",
      "19                      0.038187  \n",
      "20                      0.036547  \n",
      "21                      0.137478  \n",
      "22                      0.810383  \n",
      "23                      0.959673  \n",
      "24                      0.964460  \n",
      "25                      0.986923  \n",
      "26                      0.080912  \n",
      "27                      0.836706  \n",
      "28                      0.008903  \n",
      "29                      0.980886  \n",
      "30                      0.610295  \n",
      "31                      0.331356  \n",
      "32                      0.378752  \n",
      "33                      0.967385  \n",
      "34                      0.017422  \n",
      "35                      0.046360  \n",
      "36                      0.985644  \n",
      "37                      0.215058  \n",
      "38                      0.809455  \n",
      "39                      0.875765  \n",
      "40                      0.022715  \n",
      "41                      0.994145  \n",
      "42                      0.986155  \n",
      "43                      0.947686  \n",
      "44                      0.995244  \n",
      "45                      0.054710  \n",
      "46                      0.771957  \n",
      "47                      0.962446  \n",
      "                         Feature  Importance\n",
      "49             recent_goals_away    0.065933\n",
      "47                     delta_ppg    0.057278\n",
      "50            average_goals_home    0.049872\n",
      "69                goal_away_team    0.049858\n",
      "52        avarage_conceeded_away    0.047958\n",
      "..                           ...         ...\n",
      "67                  defence_home    0.000000\n",
      "68                goal_home_team    0.000000\n",
      "2                       home_ppg    0.000000\n",
      "30  over_35_percentage_pre_match    0.000000\n",
      "9            away_team_red_cards    0.000000\n",
      "\n",
      "[72 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train = X[preprocessed_df['Game Week'] <= cut_off]\n",
    "y_train = y[preprocessed_df['Game Week'] <= cut_off]\n",
    "X_test = X[preprocessed_df['Game Week'] > cut_off]\n",
    "y_test = y[preprocessed_df['Game Week'] > cut_off]\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb_model = XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train XGBoost model on the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob = xgb_model.predict_proba(X_test)[:, 1]  # Probability of BTTS (1)\n",
    "\n",
    "# Apply custom thresholding\n",
    "y_pred_custom = np.where(y_pred_prob >= 0.6, 1, np.where(y_pred_prob <= 0.4, 0, np.nan))\n",
    "\n",
    "# Filter out NaN values for both y_pred_custom and y_test\n",
    "mask = ~np.isnan(y_pred_custom)\n",
    "y_test_filtered = y_test[mask].reset_index(drop=True)\n",
    "y_pred_filtered = pd.Series(y_pred_custom[mask]).reset_index(drop=True)\n",
    "\n",
    "# Calculate accuracy on filtered predictions\n",
    "accuracy = accuracy_score(y_test_filtered, y_pred_filtered)\n",
    "print(f\"Custom threshold accuracy (excluding values between 0.4 and 0.6): {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display a comparison DataFrame for manual inspection\n",
    "comparison_df = pd.DataFrame({\n",
    "    'True Value (y_test)': y_test_filtered,\n",
    "    'Predicted Value (y_pred)': y_pred_filtered,\n",
    "    'Predicted Probability (BTTS)': y_pred_prob[mask]\n",
    "})\n",
    "print(comparison_df)\n",
    "\n",
    "# Get feature importance from the trained XGBoost model\n",
    "importances = xgb_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,  # Use original X_train columns\n",
    "    'Importance': importances\n",
    "})\n",
    "print(feature_importance_df.sort_values(by='Importance', ascending=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
